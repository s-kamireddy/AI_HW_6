{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OMSrix2bA678AdGi_sU4rPpQCjbB_7H-",
      "authorship_tag": "ABX9TyNfhX7h1omloYQVNNOAHuXr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7ed80912cf24ff88c0f3ee894c2dbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ebbb69cd31542a5a9b927d35d2a84a2",
              "IPY_MODEL_2ec7514de4bb43dab6a062a21090e59d",
              "IPY_MODEL_02350b7a383e434a9e817816dc72396a"
            ],
            "layout": "IPY_MODEL_c1a3ece55d0a4a169e6e8efc8729fd4a"
          }
        },
        "8ebbb69cd31542a5a9b927d35d2a84a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7fe4ee607f14dd19ea8a3d96fba52a5",
            "placeholder": "​",
            "style": "IPY_MODEL_2de83b6a973b4c4ba74398dcd57232d7",
            "value": "Map: 100%"
          }
        },
        "2ec7514de4bb43dab6a062a21090e59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dee7c1c690843bb9524b5a29e41a999",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97ca458312d24f6da1248a751049dc49",
            "value": 500
          }
        },
        "02350b7a383e434a9e817816dc72396a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678b4d86aa274db3998b262d7fbeaceb",
            "placeholder": "​",
            "style": "IPY_MODEL_71d05ea9eae74505b74dc41cb024864f",
            "value": " 500/500 [00:02&lt;00:00, 178.80 examples/s]"
          }
        },
        "c1a3ece55d0a4a169e6e8efc8729fd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fe4ee607f14dd19ea8a3d96fba52a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de83b6a973b4c4ba74398dcd57232d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dee7c1c690843bb9524b5a29e41a999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ca458312d24f6da1248a751049dc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "678b4d86aa274db3998b262d7fbeaceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d05ea9eae74505b74dc41cb024864f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-kamireddy/AI_HW_6/blob/main/AI_HW_6_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zQRVSITnugcw",
        "outputId": "cd2f653d-cfc1-48d4-ac2f-0b94fa8b4ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "XTnQzunbThBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93e446f-2d1c-4abf-9be8-fb6e4ae5ca1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIQsGERDjOwZ"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "NDMh9jjBJuuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data exploration and preprocessing"
      ],
      "metadata": {
        "id": "eVISMyPknRfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
        "eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(500))\n",
        "\n",
        "#print\n",
        "print(train_dataset[\"highlights\"][0])\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSCFkiMjke3p",
        "outputId": "c22031bc-0848-481c-9545-3f3259436b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John and .\n",
            "Audrey Cook were discovered alongside their daughter, Maureen .\n",
            "They were found at Tremarle Home Park in Cornwall .\n",
            "Investigators say the three died of carbon monoxide .\n",
            "poisoning .\n",
            "Dataset({\n",
            "    features: ['article', 'highlights', 'id'],\n",
            "    num_rows: 500\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yZQ9gqjqnU_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizerFast, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "uKvOXdB3nVcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxInput = 512\n",
        "maxTarget = 128\n",
        "batchSize = 3\n",
        "modelCheckpoint = \"facebook/bart-large-cnn\""
      ],
      "metadata": {
        "id": "KqwTzj4Ks0D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained(modelCheckpoint)\n",
        "tokenizer = BartTokenizerFast.from_pretrained(modelCheckpoint)"
      ],
      "metadata": {
        "id": "Jw0UIgSss1Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [text for text in examples[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length= 512,padding = 'max_length', truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"highlights\"], max_length=128,padding = 'max_length', truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "fBhfAVLUqpbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"article\", \"highlights\", \"id\"])\n",
        "tokenized_test = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"article\", \"highlights\", \"id\"])\n",
        "tokenized_eval = eval_dataset.map(preprocess_function, batched=True, remove_columns=[\"article\", \"highlights\", \"id\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a7ed80912cf24ff88c0f3ee894c2dbf5",
            "8ebbb69cd31542a5a9b927d35d2a84a2",
            "2ec7514de4bb43dab6a062a21090e59d",
            "02350b7a383e434a9e817816dc72396a",
            "c1a3ece55d0a4a169e6e8efc8729fd4a",
            "d7fe4ee607f14dd19ea8a3d96fba52a5",
            "2de83b6a973b4c4ba74398dcd57232d7",
            "2dee7c1c690843bb9524b5a29e41a999",
            "97ca458312d24f6da1248a751049dc49",
            "678b4d86aa274db3998b262d7fbeaceb",
            "71d05ea9eae74505b74dc41cb024864f"
          ]
        },
        "id": "r2GUOSkQq7gS",
        "outputId": "4b6fa4e4-4384-43e4-d516-bfda24ca1656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7ed80912cf24ff88c0f3ee894c2dbf5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "tokenized_eval.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "JSD8LMO9RGzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_train[0])\n",
        "print(tokenized_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVdGSZQk06PC",
        "outputId": "811eb8e1-49b9-465b-ce9f-20851b9fa23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([    0,  2765,   479,  3173,  7291,   479, 29731,  7976, 14849,  1691,\n",
            "           35,   479, 13470,    35,  3933, 12936,     6,   132,   494,  1014,\n",
            "          479,  1721,   479,   121, 44964,    35,   479, 12112,    35,  3570,\n",
            "        12936,     6,   132,   494,  1014,   479,  2873,   453,     9,     5,\n",
            "          276,   284,    54,   962,    11,    10, 25156, 15987,    31,  4363,\n",
            "         6154, 24260, 15000,    74,    33,    57, 15003,   128, 34451,   728,\n",
            "         3934,  3725,    26,   452,     4,    20,  3738,     9,  2997,   891,\n",
            "          610,     8, 25478,  4350,    58,  2967,  2863,    49,  1354,     6,\n",
            "         3066, 26743,     6,    23,     5,  1830,   184,    51,  1373,    15,\n",
            "        31103,   271,   459,  2193,   861,    11,  4536, 17080,     6,  3072,\n",
            "        21690,     4,    20, 27874, 10092,    33,   122,  1357,    88,     5,\n",
            "         3257,    94,   378,     6,    19,  3725,   584,     5,   130,   962,\n",
            "          552,    19,     5,   284,    18,  4716,  2335,     6,     9,  4363,\n",
            "         6154, 24260, 15000,    31,    10, 35572,     4,  2393, 25725,    35,\n",
            "           20, 27874, 10092,    33,  1357,    88,     5,  3257,     9,   130,\n",
            "          453,     9,     5,   276,   284,    54,    58,   303,    11,    49,\n",
            "        25156, 15987,    94,   983,     4,   610,     8, 25478,  4350,    32,\n",
            "         7092,   479, 11614,  2650,    35,    20,   284,   962,   511,  4363,\n",
            "         6154, 24260, 15000,    23,    42, 15987,    23,     5, 31103,   271,\n",
            "          459,  2193,   861,    11,  4536, 17080,     6, 21690,   479,    85,\n",
            "           16,    67,  2047,    89,    21,   117,   447,  4363,  6154, 24260,\n",
            "        30956,    11,     5, 25156, 15987,     4, 21690,  1833,     8,  8801,\n",
            "         1841,    26,    42,    74,    33,  4596,    11,     5,   130,   145,\n",
            "        15003,   128, 34451,   728,  3934,   479,    83,  1565,    13, 21690,\n",
            "        16489,   925,  7957, 18395,   261,  1474,     5, 27874, 10092,    58,\n",
            "         1357,     8, 16649,   196,  2350,  1390,     4,   252,    40,  6654,\n",
            "           23,    10,   423,  1248,     4, 17264,     8, 21690,   522,  1474,\n",
            "           15,   302,    14,  4363,  6154, 24260, 15000,    56,    57,  2885,\n",
            "           25,     5,  1303,     9,   744,     4,    83,   249,  1565,    26,\n",
            "            5,  1300,     9,     5, 15000,    21,   128,  8494, 36024,     7,\n",
            "           28,    31, 17401,  2513,     9,     5,  1123, 35572,  2652, 39866,\n",
            "          154,    35,   152,   693,   314,  7716,   751,     5, 15987,   511,\n",
            "            5,  3257,     4,    85,    34,  4373,    14,     5,  8566,    74,\n",
            "           33,    57, 15003,   128, 34451,   728,   108, 14743,   154,    35,\n",
            "          152,  6430,    21,   314,   751,     5, 15987,   511,   340,     9,\n",
            "            5,  3257,   479,  8451, 16569,    31,  2320,    23,     5,  1082,\n",
            "         1487,    10,  2905, 14326,   672,     9,  4363,  6154, 24260,  1455,\n",
            "          624,     5, 15987,    23,     5,    86,    24,    21,   551,     6,\n",
            "         3691,    71,     5,  6953,     9,     5,  3738,     4,  7837,     8,\n",
            "        10689,    33,  1199,  6430,     7,     5,  8566,     4,   509,   479,\n",
            "        14915,     6,  6366,   102, 12212,     6,  4268,     6,    26,    35,\n",
            "          128,   243,    18,   182,  7018,  9828,     4,    38,  1467,     5,\n",
            "          479,  1354,     6,    79,    21,  1207,    69,    19,    69,  8562,\n",
            "            8,  4252,     4, 16225,    16,   269,   479,  4904,   955, 10488,\n",
            "        10420,     6,  3620,     6,    54,  3033,   583,     5,   891,     8,\n",
            "           49,   479,  1354,     6,    26,    35,   128,  1213,    56,  3033,\n",
            "          259,    13,   198,   843,   107,     8,    51,  1682,   479,  1235,\n",
            "            7,  1235,     4,   128,   100,    95,    64,    17,    27,    90,\n",
            "          679,    42,    34,   479,  1102,     6,    24,    16,    98,  5074,\n",
            "            8,    38,   524,    98,  6649,     6,    38,   206,    52,    70,\n",
            "           32,     6,    47,    95,   479,   218,    17,    27,    90,  1057,\n",
            "           42,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([    0, 10567,     8,   479, 50118, 37779,  5460,  4350,    58,  2967,\n",
            "         2863,    49,  1354,     6,  3066, 26743,   479, 50118,  1213,    58,\n",
            "          303,    23, 31103,   271,   459,  2193,   861,    11, 21690,   479,\n",
            "        50118, 40333,   224,     5,   130,   962,     9,  4363,  6154, 24260,\n",
            "          479, 50118,  5873,  4060,   154,   479,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1])}\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 500\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "H-xnMTpCWS-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9m7m2YQ8m0NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training(dataset, model, tokenizer, batch_size=8, epochs=10, learning_rate=1e-3, accumulation_steps=4):\n",
        "    import torch\n",
        "    from torch.utils.data import DataLoader\n",
        "    from torch.optim import Adam\n",
        "    from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    batch_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps= (len(batch_loader) // accumulation_steps + int(len(batch_loader) % accumulation_steps > 0)) * epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch}/{epochs}\")\n",
        "        running_loss = 0.0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for idx, batch in enumerate(batch_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss / accumulation_steps\n",
        "            loss.backward()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (idx + 1) % accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()  # Reset gradients for the next accumulation cycle\n",
        "                print(f\"Batch {idx + 1}/{len(batch_loader)} - Loss: {running_loss}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "            del input_ids\n",
        "            del attention_mask\n",
        "            del labels\n",
        "            del outputs\n",
        "            del loss\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        #last few batches\n",
        "        if len(batch_loader) % accumulation_steps != 0:\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            print(f\"End of epoch {epoch + 1} - Loss: {running_loss}\")\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Al7sXDKj7RKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GF3n21CX8cM",
        "outputId": "83d5376f-cf4f-43fd-a220-6a8b755d018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = training(tokenized_train, model, tokenizer, batch_size=2, epochs=1, learning_rate=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jhPv-VAPLRvT",
        "outputId": "44992877-4e46-4bea-aea0-63546809c33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1\n",
            "Batch 4/500 - Loss: 6.380910038948059\n",
            "Batch 8/500 - Loss: 15.171371936798096\n",
            "Batch 12/500 - Loss: 11.559797286987305\n",
            "Batch 16/500 - Loss: 10.052970170974731\n",
            "Batch 20/500 - Loss: 9.458039999008179\n",
            "Batch 24/500 - Loss: 8.634066104888916\n",
            "Batch 28/500 - Loss: 7.938820123672485\n",
            "Batch 32/500 - Loss: 6.535948276519775\n",
            "Batch 36/500 - Loss: 6.437809467315674\n",
            "Batch 40/500 - Loss: 6.666896224021912\n",
            "Batch 44/500 - Loss: 6.055567145347595\n",
            "Batch 48/500 - Loss: 5.952527761459351\n",
            "Batch 52/500 - Loss: 6.463042259216309\n",
            "Batch 56/500 - Loss: 5.091938853263855\n",
            "Batch 60/500 - Loss: 5.467901587486267\n",
            "Batch 64/500 - Loss: 5.833650469779968\n",
            "Batch 68/500 - Loss: 4.998159170150757\n",
            "Batch 72/500 - Loss: 5.219856858253479\n",
            "Batch 76/500 - Loss: 5.343723297119141\n",
            "Batch 80/500 - Loss: 4.9865193367004395\n",
            "Batch 84/500 - Loss: 5.290077328681946\n",
            "Batch 88/500 - Loss: 5.680011808872223\n",
            "Batch 92/500 - Loss: 4.704928994178772\n",
            "Batch 96/500 - Loss: 5.733253479003906\n",
            "Batch 100/500 - Loss: 4.874337434768677\n",
            "Batch 104/500 - Loss: 5.972468376159668\n",
            "Batch 108/500 - Loss: 5.269001364707947\n",
            "Batch 112/500 - Loss: 5.782638669013977\n",
            "Batch 116/500 - Loss: 5.547000885009766\n",
            "Batch 120/500 - Loss: 5.7504390478134155\n",
            "Batch 124/500 - Loss: 5.497771382331848\n",
            "Batch 128/500 - Loss: 5.075952172279358\n",
            "Batch 132/500 - Loss: 5.516290068626404\n",
            "Batch 136/500 - Loss: 5.528822898864746\n",
            "Batch 140/500 - Loss: 5.210213303565979\n",
            "Batch 144/500 - Loss: 5.644216179847717\n",
            "Batch 148/500 - Loss: 4.3183271288871765\n",
            "Batch 152/500 - Loss: 5.2672717571258545\n",
            "Batch 156/500 - Loss: 4.994920551776886\n",
            "Batch 160/500 - Loss: 4.460495710372925\n",
            "Batch 164/500 - Loss: 5.031650900840759\n",
            "Batch 168/500 - Loss: 4.898132681846619\n",
            "Batch 172/500 - Loss: 4.8586671352386475\n",
            "Batch 176/500 - Loss: 4.635514974594116\n",
            "Batch 180/500 - Loss: 4.695515513420105\n",
            "Batch 184/500 - Loss: 5.461456298828125\n",
            "Batch 188/500 - Loss: 5.691234827041626\n",
            "Batch 192/500 - Loss: 5.162960946559906\n",
            "Batch 196/500 - Loss: 4.589323401451111\n",
            "Batch 200/500 - Loss: 5.869939208030701\n",
            "Batch 204/500 - Loss: 5.460429668426514\n",
            "Batch 208/500 - Loss: 5.042312800884247\n",
            "Batch 212/500 - Loss: 5.204256892204285\n",
            "Batch 216/500 - Loss: 4.39847731590271\n",
            "Batch 220/500 - Loss: 5.1375672817230225\n",
            "Batch 224/500 - Loss: 4.598573565483093\n",
            "Batch 228/500 - Loss: 4.789676606655121\n",
            "Batch 232/500 - Loss: 5.098636567592621\n",
            "Batch 236/500 - Loss: 4.405136346817017\n",
            "Batch 240/500 - Loss: 4.877487301826477\n",
            "Batch 244/500 - Loss: 5.234177589416504\n",
            "Batch 248/500 - Loss: 5.132705926895142\n",
            "Batch 252/500 - Loss: 4.600095629692078\n",
            "Batch 256/500 - Loss: 5.554968357086182\n",
            "Batch 260/500 - Loss: 4.849734544754028\n",
            "Batch 264/500 - Loss: 4.589366555213928\n",
            "Batch 268/500 - Loss: 5.562124967575073\n",
            "Batch 272/500 - Loss: 4.437770068645477\n",
            "Batch 276/500 - Loss: 5.291105329990387\n",
            "Batch 280/500 - Loss: 4.30056232213974\n",
            "Batch 284/500 - Loss: 5.7189857959747314\n",
            "Batch 288/500 - Loss: 4.736161172389984\n",
            "Batch 292/500 - Loss: 5.377927541732788\n",
            "Batch 296/500 - Loss: 5.110506176948547\n",
            "Batch 300/500 - Loss: 5.016730785369873\n",
            "Batch 304/500 - Loss: 3.8777878880500793\n",
            "Batch 308/500 - Loss: 3.7030805945396423\n",
            "Batch 312/500 - Loss: 6.614623546600342\n",
            "Batch 316/500 - Loss: 4.644700706005096\n",
            "Batch 320/500 - Loss: 4.601544260978699\n",
            "Batch 324/500 - Loss: 5.602331638336182\n",
            "Batch 328/500 - Loss: 5.144294023513794\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3cb95a3e6bc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-e00e65a2e2f8>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(dataset, model, tokenizer, batch_size, epochs, learning_rate, accumulation_steps)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model state after training is complete\n",
        "torch.save(\n",
        "        model.state_dict(),\n",
        "        os.path.join(\".\", \"model-final.pt\"),\n",
        ")\n"
      ],
      "metadata": {
        "id": "VS4XCPLjTD5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Model"
      ],
      "metadata": {
        "id": "jzGgFH9w3pUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model.load_state_dict(torch.load(os.path.join(\".\", \"model-final.pt\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOqJXQyZnBES",
        "outputId": "01ebff9e-d73c-45f0-fa7e-c338c310f4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "xRZS-u5RTqoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "# Instantiate the Rouge class\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "test_loader = DataLoader(tokenized_test, batch_size=2, shuffle=True)\n",
        "\n",
        "for idx, batch in enumerate(test_loader):\n",
        "    input_ids = batch['input_ids'].to('cuda')\n",
        "    attention_mask = batch['attention_mask'].to('cuda')\n",
        "    labels = batch['labels'].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128, num_beams=4, early_stopping=True)\n",
        "\n",
        "    predictions = outputs\n",
        "    all_predictions.extend(predictions)\n",
        "    all_labels.extend(labels)\n",
        "\n",
        "    if idx % 10 == 0:\n",
        "        print(f\"Batch {idx + 1}/{len(test_loader)}\")\n",
        "\n",
        "    del input_ids\n",
        "    del attention_mask\n",
        "    del labels\n",
        "    del outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YptYS1U1Tx4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6902920-12d8-4e9a-ab27-357eee5856a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/250\n",
            "Batch 11/250\n",
            "Batch 21/250\n",
            "Batch 31/250\n",
            "Batch 41/250\n",
            "Batch 51/250\n",
            "Batch 61/250\n",
            "Batch 71/250\n",
            "Batch 81/250\n",
            "Batch 91/250\n",
            "Batch 101/250\n",
            "Batch 111/250\n",
            "Batch 121/250\n",
            "Batch 131/250\n",
            "Batch 141/250\n",
            "Batch 151/250\n",
            "Batch 161/250\n",
            "Batch 171/250\n",
            "Batch 181/250\n",
            "Batch 191/250\n",
            "Batch 201/250\n",
            "Batch 211/250\n",
            "Batch 221/250\n",
            "Batch 231/250\n",
            "Batch 241/250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QvsrSFhQtVCC",
        "outputId": "8b583cba-69b0-40f9-dabd-e4f4ed680f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50oOwzDtvRTn",
        "outputId": "35d568b3-3749-48d5-a1ab-9fe01ad0132b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "kek8HzHUtQsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load('sacrebleu')\n",
        "scores = {'rouge1':[], 'rouge2':[], 'rougeL':[], 'bleu':[]}\n",
        "\n",
        "for prediction, label in zip(all_predictions, all_labels):\n",
        "    pred_text = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "    label_text = tokenizer.decode(label, skip_special_tokens=True)\n",
        "\n",
        "    score = scorer.score(label_text, pred_text)\n",
        "\n",
        "    #bleu_score = bleu.compute(predictions=[pred_text], references= [[label_text]])\n",
        "\n",
        "    scores['rouge1'].append(score['rouge1'].fmeasure)\n",
        "    scores['rouge2'].append(score['rouge2'].fmeasure)\n",
        "    scores['rougeL'].append(score['rougeL'].fmeasure)\n",
        "    scores['bleu'].append('bleu_score')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Rouge1:', sum(scores['rouge1']) / len(scores['rouge1']))\n",
        "print('Rouge2:', sum(scores['rouge2']) / len(scores['rouge2']))\n",
        "print('RougeL:', sum(scores['rougeL']) / len(scores['rougeL']))\n",
        "#print('Bleu:',sum(scores['bleu']) / len(scores['bleu']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJipnIhTrQqV",
        "outputId": "bec2cb20-2762-4e02-a8cb-bbd023b6299b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rouge1: 0.17937228376500686\n",
            "Rouge2: 0.004593414297842033\n",
            "RougeL: 0.11295938656114883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prediction, label in zip(all_predictions, all_labels):\n",
        "    pred_text = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "    label_text = tokenizer.decode(label, skip_special_tokens=True)\n",
        "    bleu_score = bleu.compute(predictions=[pred_text], references= [[label_text]])\n",
        "\n",
        "    scores['bleu'].append(bleu_score['score'])\n",
        "\n",
        "print('Bleu:',sum(scores['bleu']) / len(scores['bleu']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DCTbWgnjd5Je",
        "outputId": "b6117309-4268-40bf-b4b9-12779f19387c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f401517b1af3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpred_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabel_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_feature_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_feature_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36m_init_writer\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;31m# Get cache file name and lock it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                 \u001b[0mcache_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_cache_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilelock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36m_create_cache_file\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mfilelock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".lock\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mfilelock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# If we have reached the max number of attempts or we are not allow to find a free name (distributed setup)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/filelock/_api.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, timeout, poll_interval, poll_intervall, blocking)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Lock %s not acquired on %s, waiting %s seconds ...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Something did go wrong, so decrement the counter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_counter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussions on hyperparameters\n",
        "\n",
        "Performance was not very accurate. Given the oppourtunity there is much that could be done to fine tune the hyperparameters for better performance, such as increasing the number of training epochs, increasing the embedding sizes, and decreasing the learning rate"
      ],
      "metadata": {
        "id": "4c1bEyGEynpL"
      }
    }
  ]
}